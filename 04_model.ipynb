{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "import scipy.stats as stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpickle file \n",
    "modeling_df = pd.read_pickle(\"./cleaned_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = modeling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,2:] #'walk_score', 'res_score', 'attraction_score','num_reviews', 'num_QA', 'num_Tips', 'num_rooms', 'min_price','max_price', 'avg_price\n",
    "\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/test/split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first split 20%\n",
    "X_train_val, X_test, y_train_val, y_test = \\\n",
    "train_test_split(X,y,test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the 3 models to compare:\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_val_scaled = scaler.transform(X_val.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train.values)\n",
    "X_val_poly = poly.transform(X_val.values)\n",
    "X_test_poly = poly.transform(X_test.values)\n",
    "\n",
    "lm_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate #3 models\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "print(f'Linear Regression val R^2: {lm.score(X_val, y_val):.3f}')\n",
    "\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "print(f'Ridge Regression val R^2: {lm_reg.score(X_val_scaled, y_val):.3f}')\n",
    "\n",
    "lm_poly.fit(X_train_poly, y_train)\n",
    "print(f'Degree 2 polynomial regression val R^2: {lm_poly.score(X_val_poly, y_val):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10) #hold out 20% of the data for final testing\n",
    "\n",
    "#this helps with the way kf will generate indices below\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the CV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm_reg = Ridge(alpha=1)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_scaled,y)\n",
    "print(f'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.rating\n",
    "X_= df.drop(['rating','walk_perfect', 'hotel_name'], axis = 1)\n",
    "X = pd.concat([X_, dummies[['walk_perfect']]], axis = 1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10,-2,100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(normalize = True)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha = a)\n",
    "    ridge.fit(X, y)\n",
    "    coefs.append(ridge.coef_)\n",
    "    \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data 60 - 20 - 20 train/val/test\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2 = Ridge(alpha = 4, normalize = True)\n",
    "ridge2.fit(X_train, y_train)             # Fit a ridge regression on the training data\n",
    "pred2 = ridge2.predict(X_test)           # Use this model to predict the test data\n",
    "print(pd.Series(ridge2.coef_, index = X.columns)) # Print coefficients\n",
    "print(mean_squared_error(y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using CV to choose alpha\n",
    "ridgecv = RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error', normalize = True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge4 = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "ridge4.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, ridge4.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge4.fit(X, y)\n",
    "pd.Series(ridge4.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-walk_score\n",
    "y, X = patsy.dmatrices('rating ~  walk_perfect + attraction_score+num_QA+num_rooms+min_price+ max_price+avg_price', data=df, return_type=\"dataframe\")\n",
    "#hotel_name', 'rating', 'walk_score', 'res_score', 'attraction_score','num_reviews', 'num_QA', 'num_Tips', 'num_rooms', 'min_price','max_price', 'avg_price'\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using logged variables - walk_score - res_score - log_num_reviews - num_QA - attraction_score - walk_perfect\n",
    "\n",
    "y, X = patsy.dmatrices('rating ~  log_num_rooms + log_min_price + log_num_Tips + log_avg_price + max_price + min_price', data=df, return_type=\"dataframe\")\n",
    "#hotel_name', 'rating', 'walk_score', 'res_score', 'attraction_score','num_reviews', 'num_QA', 'num_Tips', 'num_rooms', 'min_price','max_price', 'avg_price'\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "\n",
    "# Fit your model to your training set\n",
    "fit_log = model.fit()\n",
    "\n",
    "# Print summary statistics of the model's performance\n",
    "fit_log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostic_plot(x, y):\n",
    "    plt.figure(figsize=(20,5))\n",
    "   \n",
    "    rgr = LinearRegression()\n",
    "    rgr.fit(x,y)\n",
    "    pred = rgr.predict(x)\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.scatter(x,y)\n",
    "    plt.plot(x, fit_log.predict(), color='blue',linewidth=1)\n",
    "    plt.title(\"Regression fit\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    res = y - pred\n",
    "    plt.scatter(fit_log.predict(), fit_log.resid)\n",
    "    plt.title(\"Residual plot\")\n",
    "    plt.xlabel(\"prediction\")\n",
    "    plt.ylabel(\"residuals\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "   \n",
    "    stats.probplot(fit_log, dist=\"norm\", plot=plt)\n",
    "    plt.title(\"Normal Q-Q plot\")\n",
    "    \n",
    "#X = df.iloc[:, 2:]\n",
    "#y = df.iloc[:, 1]\n",
    "diagnostic_plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df['resid'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 2:]\n",
    "y = df.iloc[:, 1]\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "\n",
    "df['predict']=lr.predict(X)\n",
    "df['resid']=y - df.predict\n",
    "with sns.axes_style('white'):\n",
    "    plot=df.plot(kind='scatter',\n",
    "                  x='predict',y='resid',alpha=0.2,figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(fit_log.predict(), fit_log.resid);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "# Choose the predictor variables, here all but the first which is the response variable\n",
    "# This model is analogous to the Y ~ X1 + X2 + X3 + X4 + X5 + X6 model\n",
    "X = df.iloc[:, 2:]\n",
    "\n",
    "# Choose the response variable(s)\n",
    "y = df.iloc[:, 1]\n",
    "\n",
    "# Fit the model to the full dataset\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "lr.score(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
